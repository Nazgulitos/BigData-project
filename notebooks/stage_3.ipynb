{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb0ed7a",
   "metadata": {},
   "source": [
    "## Stage 3: Predictive Data Analytics\n",
    "\n",
    "### Imports and Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc12d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = \"team15\"\n",
    "\n",
    "# location of your Hive database in HDFS\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(\"{team} - spark ML\".format(team))\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .config(\"spark.sql.avro.compression.codec\", \"snappy\")\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created.\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "#We can also add\n",
    "# .config(\"spark.sql.catalogImplementation\",\"hive\")\\ \n",
    "# But this is the default configuration\n",
    "# You can switch to Spark Catalog by setting \"in-memory\" for \"spark.sql.catalogImplementation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3f496",
   "metadata": {},
   "source": [
    "### Load data from Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d4b65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()\n",
    "# spark.sql(\"USE team15_projectdb\").show()\n",
    "# spark.sql(\"SHOW TABLES\").show()\n",
    "# spark.sql(\"SELECT * FROM <db_name>.<table_name>\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42bdc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all databases\n",
    "\n",
    "print(spark.catalog.listDatabases())\n",
    "# spark.sql(\"SHOW DATABASES;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597ab429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all tables\n",
    "\n",
    "print(spark.catalog.listTables(\"team15_projectdb\"))\n",
    "# spark.sql(\"USE team15_projectdb;\")\n",
    "# print(spark.sql(\"SHOW TABLES;\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Hive table\n",
    "\n",
    "emps = spark.read.format(\"avro\").table('team15_projectdb.employees_part')\n",
    "\n",
    "# Creates a temporary view\n",
    "# emps.createOrReplaceTempView('employees') \n",
    "\n",
    "depts = spark.read.format(\"avro\").table('team15_projectdb.departments')\n",
    "\n",
    "# Creates a temporary view\n",
    "# depts.createOrReplaceTempView('departments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f589b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some queries\n",
    "\n",
    "emps.printSchema()\n",
    "depts.printSchema()\n",
    "\n",
    "spark.sql(\"SELECT * FROM employees WHERE deptno=10\").show()\n",
    "\n",
    "spark.sql(\"SELECT * FROM departments\").show()\n",
    "\n",
    "spark.sql(\"SELECT AVG(SAL) FROM employees;\").show()\n",
    "\n",
    "spark.sql(\"SELECT * from employees where comm is NULL;\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce77715",
   "metadata": {},
   "source": [
    "### Data prep for ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7648ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, sin, cos, pi, hour, minute, dayofmonth, dayofweek, year as f_year\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Loading Data ---\")\n",
    "df_flights = spark.table(f\"{hive_db_name}.{hive_table_name}\")\n",
    "df_flights.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa721127",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Preprocessing Data ---\")\n",
    "# 1. Select relevant features & cast target\n",
    "# CRUCIAL: Only use features known BEFORE flight departure/cancellation decision\n",
    "selected_features_raw = [\n",
    "    \"Year\", \"Month\", \"DayofMonth\", \"DayOfWeek\",\n",
    "    \"CRSDepTime\", \"CRSElapsedTime\",\n",
    "    \"Origin\", \"Dest\", \"Distance\", \"Cancelled\"\n",
    "]\n",
    "df_processed = df_flights.select(selected_features_raw)\n",
    "df_processed = df_processed.withColumn(\"Cancelled\", col(\"Cancelled\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867974c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Handle Missing Values (simple drop for this example, consider imputation)\n",
    "df_processed = df_processed.na.drop()\n",
    "print(f\"Data count after NA drop: {df_processed.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929ae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Time/Date Feature Engineering\n",
    "def parse_time_hour_udf(time_str):\n",
    "    if time_str is None: return None\n",
    "    try: return int(time_str.split(':')[0])\n",
    "    except: return None\n",
    "\n",
    "def parse_time_minute_udf(time_str):\n",
    "    if time_str is None: return None\n",
    "    try: return int(time_str.split(':')[1])\n",
    "    except: return None\n",
    "\n",
    "udf_parse_hour = udf(parse_time_hour_udf, IntegerType())\n",
    "udf_parse_minute = udf(parse_time_minute_udf, IntegerType())\n",
    "\n",
    "df_processed = df_processed.withColumn(\"ScheduledDepHour\", udf_parse_hour(col(\"CRSDepTime\")))\n",
    "df_processed = df_processed.withColumn(\"ScheduledDepMinute\", udf_parse_minute(col(\"CRSDepTime\")))\n",
    "df_processed = df_processed.na.drop(subset=[\"ScheduledDepHour\", \"ScheduledDepMinute\"])\n",
    "\n",
    "df_processed = df_processed.withColumn(\"DepHour_sin\", sin(2 * pi() * col(\"ScheduledDepHour\") / 24.0))\n",
    "df_processed = df_processed.withColumn(\"DepHour_cos\", cos(2 * pi() * col(\"ScheduledDepHour\") / 24.0))\n",
    "df_processed = df_processed.withColumn(\"Month_sin\", sin(2 * pi() * col(\"Month\") / 12.0))\n",
    "df_processed = df_processed.withColumn(\"Month_cos\", cos(2 * pi() * col(\"Month\") / 12.0))\n",
    "df_processed = df_processed.withColumn(\"DayOfMonth_sin\", sin(2 * pi() * col(\"DayofMonth\") / 31.0)) # Approx.\n",
    "df_processed = df_processed.withColumn(\"DayOfMonth_cos\", cos(2 * pi() * col(\"DayofMonth\") / 31.0))\n",
    "df_processed = df_processed.withColumn(\"DayOfWeek_sin\", sin(2 * pi() * col(\"DayOfWeek\") / 7.0))\n",
    "df_processed = df_processed.withColumn(\"DayOfWeek_cos\", cos(2 * pi() * col(\"DayOfWeek\") / 7.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Categorical Feature Encoding\n",
    "categorical_cols = [\"Origin\", \"Dest\"]\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_index\", handleInvalid=\"keep\") for c in categorical_cols]\n",
    "encoders = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=indexer.getOutputCol()+\"_ohe\") for indexer in indexers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be0a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Numerical Feature Scaling\n",
    "numerical_cols_raw = [\"Distance\", \"CRSElapsedTime\", \"Year\"] # Year is not cyclical in the same way but can be scaled\n",
    "cyclical_cols_engineered = [\n",
    "    \"DepHour_sin\", \"DepHour_cos\", \"Month_sin\", \"Month_cos\",\n",
    "    \"DayOfMonth_sin\", \"DayOfMonth_cos\", \"DayOfWeek_sin\", \"DayOfWeek_cos\"\n",
    "]\n",
    "# Assemble numerical features for scaling\n",
    "temp_numerical_assembler_inputs = numerical_cols_raw + cyclical_cols_engineered\n",
    "temp_numerical_assembler = VectorAssembler(inputCols=temp_numerical_assembler_inputs, outputCol=\"temp_numerical_features\", handleInvalid=\"keep\")\n",
    "scaler = StandardScaler(inputCol=\"temp_numerical_features\", outputCol=\"scaled_numerical_features\", withStd=True, withMean=False) # Mean can be sensitive to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e863d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Assemble Final Features Vector\n",
    "final_assembler_input_cols = [encoder.getOutputCol() for encoder in encoders] + [\"scaled_numerical_features\"]\n",
    "vector_assembler = VectorAssembler(inputCols=final_assembler_input_cols, outputCol=\"features\", handleInvalid=\"keep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ffe7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Split Data ---\n",
    "(train_data, test_data) = df_processed.randomSplit([0.8, 0.2], seed=42)\n",
    "train_data.cache() # Cache for repeated use in CV\n",
    "test_data.cache()\n",
    "print(f\"Training data count: {train_data.count()}, Test data count: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab9b1b",
   "metadata": {},
   "source": [
    "### ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f79b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Define Models, Pipelines, and Tuning ---\n",
    "lr = LogisticRegression(labelCol=\"Cancelled\", featuresCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"Cancelled\", featuresCol=\"features\", seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pre-processing stages (common for both models)\n",
    "preprocessing_stages = indexers + encoders + [temp_numerical_assembler, scaler, vector_assembler]\n",
    "\n",
    "pipeline_lr = Pipeline(stages=preprocessing_stages + [lr])\n",
    "pipeline_rf = Pipeline(stages=preprocessing_stages + [rf])\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Cancelled\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "cv_lr = CrossValidator(estimator=pipeline_lr, estimatorParamMaps=paramGrid_lr, evaluator=evaluator, numFolds=3, parallelism=4, seed=42)\n",
    "cv_rf = CrossValidator(estimator=pipeline_rf, estimatorParamMaps=paramGrid_rf, evaluator=evaluator, numFolds=3, parallelism=4, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70548561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training Logistic Regression ---\")\n",
    "cv_model_lr = cv_lr.fit(train_data)\n",
    "best_model_lr = cv_model_lr.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training Random Forest ---\")\n",
    "cv_model_rf = cv_rf.fit(train_data)\n",
    "best_model_rf = cv_model_rf.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate Models ---\n",
    "print(\"--- Evaluating Models on Test Data ---\")\n",
    "predictions_lr = best_model_lr.transform(test_data)\n",
    "predictions_rf = best_model_rf.transform(test_data)\n",
    "\n",
    "auc_pr_lr = evaluator.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_metrics(predictions_df, label_col=\"Cancelled\", pred_col=\"prediction\"):\n",
    "    \"\"\"Calculates and returns detailed classification metrics.\"\"\"\n",
    "    preds_and_labels = predictions_df.select(pred_col, label_col).rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "    metrics = MulticlassMetrics(preds_and_labels)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        \"confusion_matrix\": metrics.confusionMatrix().toArray().tolist(),\n",
    "        \"precision_0\": metrics.precision(0.0),\n",
    "        \"recall_0\": metrics.recall(0.0),\n",
    "        \"f1_0\": metrics.fMeasure(0.0),\n",
    "        \"precision_1\": metrics.precision(1.0), # For Cancelled\n",
    "        \"recall_1\": metrics.recall(1.0),       # For Cancelled\n",
    "        \"f1_1\": metrics.fMeasure(1.0),         # For Cancelled\n",
    "        \"accuracy\": metrics.accuracy\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_metrics_lr = get_detailed_metrics(predictions_lr)\n",
    "print(f\"Logistic Regression - Test AreaUnderPR: {auc_pr_lr}\")\n",
    "print(f\"Logistic Regression - Test Precision (Cancelled): {detailed_metrics_lr['precision_1']}\")\n",
    "print(f\"Logistic Regression - Test Recall (Cancelled): {detailed_metrics_lr['recall_1']}\")\n",
    "print(f\"Logistic Regression - Test F1 (Cancelled): {detailed_metrics_lr['f1_1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcbb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_rf = evaluator.evaluate(predictions_rf)\n",
    "detailed_metrics_rf = get_detailed_metrics(predictions_rf)\n",
    "print(f\"Random Forest - Test AreaUnderPR: {auc_pr_rf}\")\n",
    "print(f\"Random Forest - Test Precision (Cancelled): {detailed_metrics_rf['precision_1']}\")\n",
    "print(f\"Random Forest - Test Recall (Cancelled): {detailed_metrics_rf['recall_1']}\")\n",
    "print(f\"Random Forest - Test F1 (Cancelled): {detailed_metrics_rf['f1_1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04083c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Models and Predictions ---\n",
    "print(\"--- Saving Models and Outputs ---\")\n",
    "model1_path_hdfs = \"project/models/flight_cancellation_lr_model\"\n",
    "model2_path_hdfs = \"project/models/flight_cancellation_rf_model\"\n",
    "\n",
    "best_model_lr.write().overwrite().save(model1_path_hdfs)\n",
    "print(f\"Saved Logistic Regression model to: {model1_path_hdfs}\")\n",
    "best_model_rf.write().overwrite().save(model2_path_hdfs)\n",
    "print(f\"Saved Random Forest model to: {model2_path_hdfs}\")\n",
    "\n",
    "predictions_lr.select(\"Cancelled\", \"prediction\") \\\n",
    "    .coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model1_lr_predictions\")\n",
    "print(\"Saved LR predictions to project/output/model1_lr_predictions\")\n",
    "\n",
    "predictions_rf.select(\"Cancelled\", \"prediction\") \\\n",
    "    .coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model2_rf_predictions\")\n",
    "print(\"Saved RF predictions to project/output/model2_rf_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c77de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Evaluation Comparison ---\n",
    "evaluation_summary_data = [\n",
    "    (\"Logistic Regression\", auc_pr_lr, detailed_metrics_lr['precision_1'], detailed_metrics_lr['recall_1'], detailed_metrics_lr['f1_1']),\n",
    "    (\"Random Forest\",       auc_pr_rf, detailed_metrics_rf['precision_1'], detailed_metrics_rf['recall_1'], detailed_metrics_rf['f1_1'])\n",
    "]\n",
    "eval_schema = [\"ModelName\", \"AreaUnderPR\", \"Precision_Cancelled\", \"Recall_Cancelled\", \"F1_Score_Cancelled\"]\n",
    "evaluation_df = spark.createDataFrame(evaluation_summary_data, schema=eval_schema)\n",
    "evaluation_df.show(truncate=False)\n",
    "evaluation_df.coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model_evaluation_comparison\")\n",
    "print(\"Saved evaluation comparison to project/output/model_evaluation_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.unpersist()\n",
    "test_data.unpersist()\n",
    "spark.stop()\n",
    "print(\"--- Pipeline Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846a3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cf607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
