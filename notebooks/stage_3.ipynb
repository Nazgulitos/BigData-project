{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bb0ed7a",
   "metadata": {},
   "source": [
    "## Stage 3: Predictive Data Analytics\n",
    "\n",
    "### Imports and Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc12d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring non-Spark config property: hive.metastore.uris\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/08 07:09:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/08 07:09:09 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/08 07:09:09 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "25/05/08 07:09:10 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.\n",
      "25/05/08 07:09:10 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session Created.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "team = \"team15\"\n",
    "warehouse = \"project/hive/warehouse\"\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .appName(f\"{team} - spark ML\")\\\n",
    "        .master(\"yarn\")\\\n",
    "        .config(\"hive.metastore.uris\", \"thrift://hadoop-02.uni.innopolis.ru:9883\")\\\n",
    "        .config(\"spark.sql.warehouse.dir\", warehouse)\\\n",
    "        .enableHiveSupport()\\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(\"Spark Session Created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3f496",
   "metadata": {},
   "source": [
    "### Load data from Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42bdc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           namespace|\n",
      "+--------------------+\n",
      "|             default|\n",
      "|             retake1|\n",
      "|             root_db|\n",
      "|                show|\n",
      "|     team0_projectdb|\n",
      "|    team11_projectdb|\n",
      "|           team12_db|\n",
      "|team12_hive_proje...|\n",
      "|    team12_projectdb|\n",
      "|    team13_projectdb|\n",
      "|    team14_projectdb|\n",
      "|    team15_projectdb|\n",
      "|    team16_projectdb|\n",
      "|    team18_projectdb|\n",
      "|    team19_projectdb|\n",
      "|     team1_projectdb|\n",
      "|    team20_projectdb|\n",
      "| team21_projectdb_v2|\n",
      "| team21_projectdb_v3|\n",
      "| team21_projectdb_v4|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all databases\n",
    "\n",
    "spark.sql(\"SHOW DATABASES;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "597ab429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+-----------+\n",
      "|       namespace|           tableName|isTemporary|\n",
      "+----------------+--------------------+-----------+\n",
      "|team15_projectdb|             airport|      false|\n",
      "|team15_projectdb|   airport_optimized|      false|\n",
      "|team15_projectdb|  cancellationreason|      false|\n",
      "|team15_projectdb|cancellationreaso...|      false|\n",
      "|team15_projectdb|              flight|      false|\n",
      "|team15_projectdb|    flight_optimized|      false|\n",
      "|team15_projectdb|          q1_results|      false|\n",
      "|team15_projectdb|          q2_results|      false|\n",
      "|team15_projectdb|          q3_results|      false|\n",
      "|team15_projectdb|          q4_results|      false|\n",
      "|team15_projectdb|          q5_results|      false|\n",
      "|team15_projectdb|          q6_results|      false|\n",
      "+----------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List all tables\n",
    "\n",
    "hive_db_name = f\"{team}_projectdb\"\n",
    "spark.sql(f\"USE {hive_db_name};\")\n",
    "spark.sql(\"SHOW TABLES;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d4d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Hive tables\n",
    "\n",
    "airport = spark.read.format(\"avro\").table(f'{hive_db_name}.airport')\n",
    "flight = spark.read.format(\"avro\").table(f'{hive_db_name}.flight')\n",
    "cancellationreason = spark.read.format(\"avro\").table(f'{hive_db_name}.cancellationreason')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f589b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- code: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- flightid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofmonth: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- deptime: double (nullable = true)\n",
      " |-- crsdeptime: double (nullable = true)\n",
      " |-- arrtime: double (nullable = true)\n",
      " |-- crsarrtime: double (nullable = true)\n",
      " |-- actualelapsedtime: double (nullable = true)\n",
      " |-- crselapsedtime: double (nullable = true)\n",
      " |-- airtime: double (nullable = true)\n",
      " |-- arrdelay: double (nullable = true)\n",
      " |-- depdelay: double (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- taxiin: double (nullable = true)\n",
      " |-- taxiout: double (nullable = true)\n",
      " |-- cancelled: double (nullable = true)\n",
      " |-- cancellationcode: string (nullable = true)\n",
      " |-- diverted: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- code: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run some queries\n",
    "\n",
    "airport.printSchema()\n",
    "flight.printSchema()\n",
    "cancellationreason.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72ccfa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 07:10:26 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n",
      "[Stage 0:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+----------------+\n",
      "|flightid|cancelled|cancellationcode|\n",
      "+--------+---------+----------------+\n",
      "| 6617976|      0.0|            NULL|\n",
      "| 6617977|      0.0|            NULL|\n",
      "| 6617978|      0.0|            NULL|\n",
      "| 6617979|      0.0|            NULL|\n",
      "| 6617980|      0.0|            NULL|\n",
      "| 6617981|      0.0|            NULL|\n",
      "| 6617982|      0.0|            NULL|\n",
      "| 6617983|      0.0|            NULL|\n",
      "| 6617984|      0.0|            NULL|\n",
      "| 6617985|      0.0|            NULL|\n",
      "+--------+---------+----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT flightid, cancelled, cancellationcode FROM flight LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4f65c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|code|\n",
      "+----+\n",
      "| ABE|\n",
      "| ABI|\n",
      "| ABQ|\n",
      "| ABR|\n",
      "| ABY|\n",
      "| ACK|\n",
      "| ACT|\n",
      "| ACV|\n",
      "| ACY|\n",
      "| ADK|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM airport LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c32d7313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+\n",
      "|code|description|\n",
      "+----+-----------+\n",
      "|   A|    Carrier|\n",
      "|   B|    Weather|\n",
      "|   C|        NAS|\n",
      "|   D|   Security|\n",
      "+----+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM cancellationreason LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce77715",
   "metadata": {},
   "source": [
    "### Data prep for ML modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7648ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, sin, cos, pi, hour, minute, dayofmonth, dayofweek, year as f_year\n",
    "from pyspark.sql.types import IntegerType, StringType, DoubleType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccb70af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- flightid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofmonth: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- deptime: double (nullable = true)\n",
      " |-- crsdeptime: double (nullable = true)\n",
      " |-- arrtime: double (nullable = true)\n",
      " |-- crsarrtime: double (nullable = true)\n",
      " |-- actualelapsedtime: double (nullable = true)\n",
      " |-- crselapsedtime: double (nullable = true)\n",
      " |-- airtime: double (nullable = true)\n",
      " |-- arrdelay: double (nullable = true)\n",
      " |-- depdelay: double (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- taxiin: double (nullable = true)\n",
      " |-- taxiout: double (nullable = true)\n",
      " |-- cancelled: double (nullable = true)\n",
      " |-- cancellationcode: string (nullable = true)\n",
      " |-- diverted: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hive_table_name = \"flight\"\n",
    "df = spark.table(f\"{hive_db_name}.{hive_table_name}\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539e6223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "|flightid|year|month|dayofmonth|dayofweek|deptime|crsdeptime|arrtime|crsarrtime|actualelapsedtime|crselapsedtime|airtime|arrdelay|depdelay|origin|dest|distance|taxiin|taxiout|cancelled|cancellationcode|diverted|\n",
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "| 6617976|2017|   11|        12|        7| 2049.0|    2055.0| 2144.0|    2205.0|            115.0|         130.0|   97.0|   -21.0|    -6.0|   DCA| MKE|   634.0|   3.0|   15.0|      0.0|            NULL|     0.0|\n",
      "| 6617977|2017|   11|        12|        7| 1430.0|    1430.0| 1523.0|    1535.0|            113.0|         125.0|  100.0|   -12.0|     0.0|   DCA| MKE|   634.0|   3.0|   10.0|      0.0|            NULL|     0.0|\n",
      "| 6617978|2017|   11|        12|        7| 1308.0|    1305.0| 1448.0|    1500.0|            160.0|         175.0|  142.0|   -12.0|     3.0|   DCA| MSY|   969.0|   5.0|   13.0|      0.0|            NULL|     0.0|\n",
      "| 6617979|2017|   11|        12|        7| 1904.0|    1855.0| 2043.0|    2050.0|            159.0|         175.0|  148.0|    -7.0|     9.0|   DCA| MSY|   969.0|   2.0|    9.0|      0.0|            NULL|     0.0|\n",
      "| 6617980|2017|   11|        12|        7| 1640.0|    1645.0| 1819.0|    1845.0|            159.0|         180.0|  146.0|   -26.0|    -5.0|   DCA| OMA|  1012.0|   3.0|   10.0|      0.0|            NULL|     0.0|\n",
      "| 6617981|2017|   11|        12|        7| 2124.0|    1955.0| 2228.0|    2115.0|             64.0|          80.0|   49.0|    73.0|    89.0|   DCA| PVD|   356.0|   3.0|   12.0|      0.0|            NULL|     0.0|\n",
      "| 6617982|2017|   11|        12|        7| 1137.0|    1145.0| 1242.0|    1305.0|             65.0|          80.0|   48.0|   -23.0|    -8.0|   DCA| PVD|   356.0|   4.0|   13.0|      0.0|            NULL|     0.0|\n",
      "| 6617983|2017|   11|        12|        7|  859.0|     755.0| 1016.0|     915.0|            137.0|         140.0|  115.0|    61.0|    64.0|   DCA| STL|   719.0|   3.0|   19.0|      0.0|            NULL|     0.0|\n",
      "| 6617984|2017|   11|        12|        7| 1154.0|    1155.0| 1309.0|    1320.0|            135.0|         145.0|  114.0|   -11.0|    -1.0|   DCA| STL|   719.0|   3.0|   18.0|      0.0|            NULL|     0.0|\n",
      "| 6617985|2017|   11|        12|        7| 1851.0|    1855.0| 2002.0|    2015.0|            131.0|         140.0|  107.0|   -13.0|    -4.0|   DCA| STL|   719.0|   8.0|   16.0|      0.0|            NULL|     0.0|\n",
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae985a1a-8cf9-40f2-b0ae-fce22ea7e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:===========================================================(7 + 0) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rows: 18505725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Total number of rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08433cfa-b224-45fa-abec-5e585fbce54a",
   "metadata": {},
   "source": [
    "#### Selecting features (drop unnecessary columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "619cf14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['flightid', 'year', 'month', 'dayofmonth', 'dayofweek', 'deptime', 'crsdeptime', 'arrtime', 'crsarrtime', 'actualelapsedtime', 'crselapsedtime', 'airtime', 'arrdelay', 'depdelay', 'origin', 'dest', 'distance', 'taxiin', 'taxiout', 'cancelled', 'cancellationcode', 'diverted']\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5748fb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:==================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "|flightid|year|month|dayofmonth|dayofweek|deptime|crsdeptime|arrtime|crsarrtime|actualelapsedtime|crselapsedtime|airtime|arrdelay|depdelay|origin|dest|distance|taxiin|taxiout|cancelled|cancellationcode|diverted|\n",
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "|       0|   0|    0|         0|        0| 256081|         0| 271763|         0|           309166|            23| 309166|  311764|  261033|     0|   0|       0|271764| 263393|        0|        18240587|       0|\n",
      "+--------+----+-----+----------+---------+-------+----------+-------+----------+-----------------+--------------+-------+--------+--------+------+----+--------+------+-------+---------+----------------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_counts = df.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b021ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- dayofmonth: integer (nullable = true)\n",
      " |-- dayofweek: integer (nullable = true)\n",
      " |-- crsdeptime: double (nullable = true)\n",
      " |-- crsarrtime: double (nullable = true)\n",
      " |-- crselapsedtime: double (nullable = true)\n",
      " |-- origin: string (nullable = true)\n",
      " |-- dest: string (nullable = true)\n",
      " |-- distance: double (nullable = true)\n",
      " |-- cancelled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# features = [\n",
    "#     # 'flightid',\n",
    "#     'year', 'month', 'dayofmonth', 'dayofweek',          # timestamps (will be transformed later)\n",
    "#     'deptime', 'crsdeptime', 'arrtime', 'crsarrtime',    # timestamps (will be transformed later)\n",
    "#     'actualelapsedtime', 'crselapsedtime',\n",
    "#     'airtime', 'arrdelay', 'depdelay',\n",
    "#     'origin', 'dest',\n",
    "#     'distance',\n",
    "#     'taxiin', 'taxiout', 'diverted',\n",
    "#     # 'carrierdelay', 'weatherdelay', 'nasdelay', 'securitydelay', 'lateaircraftdelay',   # a lot of nulls\n",
    "# ]\n",
    "features = [\n",
    "    # 'flightid',\n",
    "    'year', 'month', 'dayofmonth', 'dayofweek',          # timestamps (will be transformed later)\n",
    "    'crsdeptime', 'crsarrtime',    # timestamps (will be transformed later)\n",
    "    'crselapsedtime',\n",
    "    'origin', 'dest',\n",
    "    'distance',\n",
    "    # 'diverted',\n",
    "    # 'carrierdelay', 'weatherdelay', 'nasdelay', 'securitydelay', 'lateaircraftdelay',   # a lot of nulls\n",
    "]\n",
    "label = \"cancelled\"\n",
    "\n",
    "df = df.select(features + [label])\n",
    "df = df.withColumn(label, F.col(label).cast(DoubleType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9fba3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|year|month|dayofmonth|dayofweek|crsdeptime|crsarrtime|crselapsedtime|origin|dest|distance|cancelled|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|2017|   11|        12|        7|    2055.0|    2205.0|         130.0|   DCA| MKE|   634.0|      0.0|\n",
      "|2017|   11|        12|        7|    1430.0|    1535.0|         125.0|   DCA| MKE|   634.0|      0.0|\n",
      "|2017|   11|        12|        7|    1305.0|    1500.0|         175.0|   DCA| MSY|   969.0|      0.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2050.0|         175.0|   DCA| MSY|   969.0|      0.0|\n",
      "|2017|   11|        12|        7|    1645.0|    1845.0|         180.0|   DCA| OMA|  1012.0|      0.0|\n",
      "|2017|   11|        12|        7|    1955.0|    2115.0|          80.0|   DCA| PVD|   356.0|      0.0|\n",
      "|2017|   11|        12|        7|    1145.0|    1305.0|          80.0|   DCA| PVD|   356.0|      0.0|\n",
      "|2017|   11|        12|        7|     755.0|     915.0|         140.0|   DCA| STL|   719.0|      0.0|\n",
      "|2017|   11|        12|        7|    1155.0|    1320.0|         145.0|   DCA| STL|   719.0|      0.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2015.0|         140.0|   DCA| STL|   719.0|      0.0|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5df5008f-7dc2-4685-9663-3f85836a7046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|sum(cancelled)|\n",
      "+--------------+\n",
      "|      265138.0|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.select(sum(\"cancelled\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e37e0-5657-4753-bfba-396156f1d59a",
   "metadata": {},
   "source": [
    "#### Dataset preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc75fd-6977-4739-9996-bc2d18ea040a",
   "metadata": {},
   "source": [
    "1. Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b1afb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after NA drop: 18505702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = df.na.drop()\n",
    "print(f\"Number of rows after NA drop: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b587b300-5921-4c3f-9eaf-edf66f5de5ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 18:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|year|month|dayofmonth|dayofweek|crsdeptime|crsarrtime|crselapsedtime|origin|dest|distance|cancelled|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|   0|    0|         0|        0|         0|         0|             0|     0|   0|       0|        0|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "null_counts = df.select([\n",
    "    F.count(F.when(F.col(c).isNull(), c)).alias(c)\n",
    "    for c in df.columns\n",
    "])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9c90c09-e3e9-4319-ac61-fd1f823048db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|year|month|dayofmonth|dayofweek|crsdeptime|crsarrtime|crselapsedtime|origin|dest|distance|cancelled|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "|2017|   11|        12|        7|    2055.0|    2205.0|         130.0|   DCA| MKE|   634.0|      0.0|\n",
      "|2017|   11|        12|        7|    1430.0|    1535.0|         125.0|   DCA| MKE|   634.0|      0.0|\n",
      "|2017|   11|        12|        7|    1305.0|    1500.0|         175.0|   DCA| MSY|   969.0|      0.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2050.0|         175.0|   DCA| MSY|   969.0|      0.0|\n",
      "|2017|   11|        12|        7|    1645.0|    1845.0|         180.0|   DCA| OMA|  1012.0|      0.0|\n",
      "|2017|   11|        12|        7|    1955.0|    2115.0|          80.0|   DCA| PVD|   356.0|      0.0|\n",
      "|2017|   11|        12|        7|    1145.0|    1305.0|          80.0|   DCA| PVD|   356.0|      0.0|\n",
      "|2017|   11|        12|        7|     755.0|     915.0|         140.0|   DCA| STL|   719.0|      0.0|\n",
      "|2017|   11|        12|        7|    1155.0|    1320.0|         145.0|   DCA| STL|   719.0|      0.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2015.0|         140.0|   DCA| STL|   719.0|      0.0|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b66a967-8718-463b-967f-1e2e7d0d17d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 22:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|sum(cancelled)|\n",
      "+--------------+\n",
      "|      265122.0|\n",
      "+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.select(sum(\"cancelled\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313f1042-9519-4274-a807-3dbbc46bc4f0",
   "metadata": {},
   "source": [
    "2. Decompose time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18ce206a-165c-4964-a59b-872ebbe0e306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+\n",
      "|year|month|dayofmonth|dayofweek|crsdeptime|crsarrtime|crselapsedtime|origin|dest|distance|cancelled|          month_sin|         month_cos|    dayofmonth_sin|     dayofmonth_cos|       dayofweek_sin|dayofweek_cos|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+\n",
      "|2017|   11|        12|        7|    2055.0|    2205.0|         130.0|   DCA| MKE|   634.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1430.0|    1535.0|         125.0|   DCA| MKE|   634.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1305.0|    1500.0|         175.0|   DCA| MSY|   969.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2050.0|         175.0|   DCA| MSY|   969.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1645.0|    1845.0|         180.0|   DCA| OMA|  1012.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1955.0|    2115.0|          80.0|   DCA| PVD|   356.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1145.0|    1305.0|          80.0|   DCA| PVD|   356.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|     755.0|     915.0|         140.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1155.0|    1320.0|         145.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2015.0|         140.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df \\\n",
    "    .withColumn(\"month_sin\", F.sin(2*math.pi * F.col(\"month\") / 12.0))\\\n",
    "    .withColumn(\"month_cos\", F.cos(2*math.pi * F.col(\"month\") / 12.0))\\\n",
    "    .withColumn(\"dayofmonth_sin\", F.sin(2*math.pi * F.col(\"dayofmonth\") / 31.0))\\\n",
    "    .withColumn(\"dayofmonth_cos\", F.cos(2*math.pi * F.col(\"dayofmonth\") / 31.0))\\\n",
    "    .withColumn(\"dayofweek_sin\", F.sin(2*math.pi * F.col(\"dayofweek\") / 7.0))\\\n",
    "    .withColumn(\"dayofweek_cos\", F.cos(2*math.pi * F.col(\"dayofweek\") / 7.0))\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd101b54-958a-4d18-9d6c-1dab40c0122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_hhmm(colname):\n",
    "    return (\n",
    "        F.floor(F.col(colname) / 100).cast(IntegerType()),\n",
    "        (F.col(colname) % 100).cast(IntegerType())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bab1f1e9-2e60-4eef-9edd-826c7454c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "|year|month|dayofmonth|dayofweek|crsdeptime|crsarrtime|crselapsedtime|origin|dest|distance|cancelled|          month_sin|         month_cos|    dayofmonth_sin|     dayofmonth_cos|       dayofweek_sin|dayofweek_cos|  crsdeptime_hr_sin|   crsdeptime_hr_cos|   crsdeptime_mn_sin|   crsdeptime_mn_cos|  crsarrtime_hr_sin|   crsarrtime_hr_cos|  crsarrtime_mn_sin|   crsarrtime_mn_cos|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "|2017|   11|        12|        7|    2055.0|    2205.0|         130.0|   DCA| MKE|   634.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|-0.8660254037844386|  0.5000000000000001|-0.49999999999999967|  0.8660254037844388|-0.5000000000000004|  0.8660254037844384|0.49999999999999994|  0.8660254037844387|\n",
      "|2017|   11|        12|        7|    1430.0|    1535.0|         125.0|   DCA| MKE|   634.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|-0.4999999999999997| -0.8660254037844388|5.66553889764798E-16|                -1.0|-0.7071067811865471| -0.7071067811865479|-0.4999999999999997| -0.8660254037844388|\n",
      "|2017|   11|        12|        7|    1305.0|    1500.0|         175.0|   DCA| MSY|   969.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|-0.2588190451025208| -0.9659258262890683| 0.49999999999999994|  0.8660254037844387|-0.7071067811865471| -0.7071067811865479|                0.0|                 1.0|\n",
      "|2017|   11|        12|        7|    1855.0|    2050.0|         175.0|   DCA| MSY|   969.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|               -1.0|-1.83697019872102...|-0.49999999999999967|  0.8660254037844388|-0.8660254037844386|  0.5000000000000001|-0.8660254037844386|  0.5000000000000001|\n",
      "|2017|   11|        12|        7|    1645.0|    1845.0|         180.0|   DCA| OMA|  1012.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|-0.8660254037844385| -0.5000000000000004|                -1.0|-1.83697019872102...|               -1.0|-1.83697019872102...|               -1.0|-1.83697019872102...|\n",
      "|2017|   11|        12|        7|    1955.0|    2115.0|          80.0|   DCA| PVD|   356.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|-0.9659258262890684|  0.2588190451025203|-0.49999999999999967|  0.8660254037844388|-0.7071067811865477|  0.7071067811865474|                1.0|2.83276944882399E-16|\n",
      "|2017|   11|        12|        7|    1145.0|    1305.0|          80.0|   DCA| PVD|   356.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|  0.258819045102521| -0.9659258262890682|                -1.0|-1.83697019872102...|-0.2588190451025208| -0.9659258262890683|0.49999999999999994|  0.8660254037844387|\n",
      "|2017|   11|        12|        7|     755.0|     915.0|         140.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0| 0.9659258262890683|-0.25881904510252063|-0.49999999999999967|  0.8660254037844388| 0.7071067811865476| -0.7071067811865475|                1.0|2.83276944882399E-16|\n",
      "|2017|   11|        12|        7|    1155.0|    1320.0|         145.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|  0.258819045102521| -0.9659258262890682|-0.49999999999999967|  0.8660254037844388|-0.2588190451025208| -0.9659258262890683| 0.8660254037844387| -0.4999999999999998|\n",
      "|2017|   11|        12|        7|    1855.0|    2015.0|         140.0|   DCA| STL|   719.0|      0.0|-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.44929359829470...|          1.0|               -1.0|-1.83697019872102...|-0.49999999999999967|  0.8660254037844388|-0.8660254037844386|  0.5000000000000001|                1.0|2.83276944882399E-16|\n",
      "+----+-----+----------+---------+----------+----------+--------------+------+----+--------+---------+-------------------+------------------+------------------+-------------------+--------------------+-------------+-------------------+--------------------+--------------------+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# time_features = ['deptime', 'crsdeptime', 'arrtime', 'crsarrtime']\n",
    "time_features = ['crsdeptime', 'crsarrtime']\n",
    "\n",
    "for tf in time_features:\n",
    "    hr, mn = split_hhmm(tf)\n",
    "    df = df \\\n",
    "        .withColumn(f\"{tf}_hr_sin\", F.sin(2*math.pi * hr / 24.0)) \\\n",
    "        .withColumn(f\"{tf}_hr_cos\", F.cos(2*math.pi * hr / 24.0)) \\\n",
    "        .withColumn(f\"{tf}_mn_sin\", F.sin(2*math.pi * mn / 60.0)) \\\n",
    "        .withColumn(f\"{tf}_mn_cos\", F.cos(2*math.pi * mn / 60.0))\n",
    "\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922e9665-173a-4c8b-8b78-2ae5481ed673",
   "metadata": {},
   "source": [
    "3. Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f102f4-09c6-4157-92c5-4660a9d21ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [\"origin\", \"dest\", \"year\"]\n",
    "num_feats = [\n",
    "    \"crselapsedtime\",\n",
    "    \"distance\",\n",
    "    # \"diverted\"\n",
    "]\n",
    "cyc_feats = (\n",
    "    [\"month_sin\", \"month_cos\", \"dayofmonth_sin\", \"dayofmonth_cos\", \"dayofweek_sin\", \"dayofweek_cos\"] +\n",
    "    [f\"{tf}_{p}_{axis}\"\n",
    "     for tf in time_features\n",
    "     for p in [\"hr\", \"mn\"]\n",
    "     for axis in [\"sin\", \"cos\"]]\n",
    ")\n",
    "all_numeric = num_feats + cyc_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f2642c3-d650-4086-b179-c1f8b672b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=f\"{c}_idx\", handleInvalid=\"keep\")\n",
    "    for c in cats\n",
    "]\n",
    "ohe = OneHotEncoder(\n",
    "    inputCols=[f\"{c}_idx\" for c in cats],\n",
    "    outputCols=[f\"{c}_ohe\" for c in cats],\n",
    "    dropLast=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4a969bd-d4bd-4fe1-b90c-c494a2896e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pre_vector_stages = indexers + [ohe]\n",
    "pre_vector_pipeline = Pipeline(stages=pre_vector_stages)\n",
    "pre_vector_model = pre_vector_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8239379d-9f71-4275-8f81-07b717cda088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 07:17:39 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------+-------------------+------------------+------------------+-------------------+-----------------------+-------------+-------------------+-----------------------+--------------------+-----------------------+-------------------+-----------------------+-------------------+-----------------------+----------------+----------------+-------------+---------+\n",
      "|crselapsedtime|distance|month_sin          |month_cos         |dayofmonth_sin    |dayofmonth_cos     |dayofweek_sin          |dayofweek_cos|crsdeptime_hr_sin  |crsdeptime_hr_cos      |crsdeptime_mn_sin   |crsdeptime_mn_cos      |crsarrtime_hr_sin  |crsarrtime_hr_cos      |crsarrtime_mn_sin  |crsarrtime_mn_cos      |origin_ohe      |dest_ohe        |year_ohe     |cancelled|\n",
      "+--------------+--------+-------------------+------------------+------------------+-------------------+-----------------------+-------------+-------------------+-----------------------+--------------------+-----------------------+-------------------+-----------------------+-------------------+-----------------------+----------------+----------------+-------------+---------+\n",
      "|130.0         |634.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-0.8660254037844386|0.5000000000000001     |-0.49999999999999967|0.8660254037844388     |-0.5000000000000004|0.8660254037844384     |0.49999999999999994|0.8660254037844387     |(362,[20],[1.0])|(360,[46],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|125.0         |634.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-0.4999999999999997|-0.8660254037844388    |5.66553889764798E-16|-1.0                   |-0.7071067811865471|-0.7071067811865479    |-0.4999999999999997|-0.8660254037844388    |(362,[20],[1.0])|(360,[46],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|175.0         |969.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-0.2588190451025208|-0.9659258262890683    |0.49999999999999994 |0.8660254037844387     |-0.7071067811865471|-0.7071067811865479    |0.0                |1.0                    |(362,[20],[1.0])|(360,[34],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|175.0         |969.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-1.0               |-1.8369701987210297E-16|-0.49999999999999967|0.8660254037844388     |-0.8660254037844386|0.5000000000000001     |-0.8660254037844386|0.5000000000000001     |(362,[20],[1.0])|(360,[34],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|180.0         |1012.0  |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-0.8660254037844385|-0.5000000000000004    |-1.0                |-1.8369701987210297E-16|-1.0               |-1.8369701987210297E-16|-1.0               |-1.8369701987210297E-16|(362,[20],[1.0])|(360,[56],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|80.0          |356.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-0.9659258262890684|0.2588190451025203     |-0.49999999999999967|0.8660254037844388     |-0.7071067811865477|0.7071067811865474     |1.0                |2.83276944882399E-16   |(362,[20],[1.0])|(360,[69],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|80.0          |356.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |0.258819045102521  |-0.9659258262890682    |-1.0                |-1.8369701987210297E-16|-0.2588190451025208|-0.9659258262890683    |0.49999999999999994|0.8660254037844387     |(362,[20],[1.0])|(360,[69],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|140.0         |719.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |0.9659258262890683 |-0.25881904510252063   |-0.49999999999999967|0.8660254037844388     |0.7071067811865476 |-0.7071067811865475    |1.0                |2.83276944882399E-16   |(362,[20],[1.0])|(360,[30],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|145.0         |719.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |0.258819045102521  |-0.9659258262890682    |-0.49999999999999967|0.8660254037844388     |-0.2588190451025208|-0.9659258262890683    |0.8660254037844387 |-0.4999999999999998    |(362,[20],[1.0])|(360,[30],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "|140.0         |719.0   |-0.5000000000000004|0.8660254037844384|0.6513724827222223|-0.7587581226927909|-2.4492935982947064E-16|1.0          |-1.0               |-1.8369701987210297E-16|-0.49999999999999967|0.8660254037844388     |-0.8660254037844386|0.5000000000000001     |1.0                |2.83276944882399E-16   |(362,[20],[1.0])|(360,[30],[1.0])|(3,[1],[1.0])|0.0      |\n",
      "+--------------+--------+-------------------+------------------+------------------+-------------------+-----------------------+-------------+-------------------+-----------------------+--------------------+-----------------------+-------------------+-----------------------+-------------------+-----------------------+----------------+----------------+-------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw_plus_ohe = pre_vector_model.transform(df)\n",
    "intermediate_cols = all_numeric + [f\"{c}_ohe\" for c in cats] + [\"cancelled\"]\n",
    "df_ohe = df_raw_plus_ohe.select(intermediate_cols)\n",
    "\n",
    "df_ohe.createOrReplaceTempView(\"flight_features_intermediate\")\n",
    "spark.sql(\"SELECT * FROM flight_features_intermediate LIMIT 10\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fb4f0f-a9e1-4e2c-9758-6d6f4704cabc",
   "metadata": {},
   "source": [
    "4. Assemble numeric + cyclical features, then scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89b1b0a9-0671-4402-a1e0-6395c5ffc18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_feats = [\n",
    "#     \"actualelapsedtime\", \"crselapsedtime\",\n",
    "#     \"airtime\", \"arrdelay\", \"depdelay\",\n",
    "#     \"distance\", \"taxiin\", \"taxiout\", \"diverted\"\n",
    "# ]\n",
    "\n",
    "# num_feats = [\n",
    "#     \"crselapsedtime\",\n",
    "#     \"distance\",\n",
    "#     # \"diverted\"\n",
    "# ]\n",
    "# cyc_feats = (\n",
    "#     [\"month_sin\", \"month_cos\", \"dayofmonth_sin\", \"dayofmonth_cos\", \"dayofweek_sin\", \"dayofweek_cos\"] +\n",
    "#     [f\"{tf}_{p}_{axis}\"\n",
    "#      for tf in time_features\n",
    "#      for p in [\"hr\", \"mn\"]\n",
    "#      for axis in [\"sin\", \"cos\"]]\n",
    "# )\n",
    "# all_numeric = num_feats + cyc_feats\n",
    "\n",
    "assembler = VectorAssembler(inputCols=all_numeric + [f\"{c}_ohe\" for c in cats], outputCol=\"features_raw\")\n",
    "scaler = StandardScaler(inputCol=\"features_raw\", outputCol=\"features\", withMean=True, withStd=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "239489c6-b6d8-4ef7-9ac1-5dff3f36d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=indexers + [ohe, assembler, scaler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bf1f20b-116a-4ab6-87d8-51656cb6b530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df)\n",
    "df_prepared = model.transform(df).select(\"features\", \"cancelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bda79a04-4ca3-4bcc-9326-077451526c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|cancelled|\n",
      "+--------------------+---------+\n",
      "|[-0.1884130372273...|      0.0|\n",
      "|[-0.2546376588361...|      0.0|\n",
      "|[0.40760855725178...|      0.0|\n",
      "|[0.40760855725178...|      0.0|\n",
      "|[0.47383317886057...|      0.0|\n",
      "|[-0.8506592533152...|      0.0|\n",
      "|[-0.8506592533152...|      0.0|\n",
      "|[-0.0559637940097...|      0.0|\n",
      "|[0.01026082759904...|      0.0|\n",
      "|[-0.0559637940097...|      0.0|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prepared.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4f92302-9029-459a-bd9d-0f37dd166b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Number of features should be = {len(all_numeric + [f'{c}_ohe' for c in cats])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd8dfb8-8fe8-4bf8-9c6d-aadf7d34b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first_vec = df_prepared.select(\"features\").first()[0]\n",
    "# print(f\"Number of features = {first_vec.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc977a0-741d-47e3-9282-b166be036d84",
   "metadata": {},
   "source": [
    "5. Balance dataset by down-sampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53ebf370-087e-4119-9981-a9c1812f0075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 50:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 18240580, 1.0: 265122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "counts = df_prepared.groupBy(\"cancelled\").count().collect()\n",
    "cnts = {row[\"cancelled\"]: row[\"count\"] for row in counts}\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "493ce452-9309-4f45-b783-4090f7ed0bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1.0: 1.0, 0.0: 0.014534735189341567}\n"
     ]
    }
   ],
   "source": [
    "min_class = min(cnts, key=cnts.get)\n",
    "maj_class = max(cnts, key=cnts.get)\n",
    "fraction = float(cnts[min_class]) / float(cnts[maj_class])\n",
    "fractions = {min_class: 1.0, maj_class: fraction}\n",
    "print(fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2270fde2-2d64-48c9-aeef-378935ebc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced = df_prepared.sampleBy(\"cancelled\", fractions, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fac7f997-152c-4535-9333-caee5776b318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|cancelled|\n",
      "+--------------------+---------+\n",
      "|[0.01026082759904...|      0.0|\n",
      "|[0.01026082759904...|      0.0|\n",
      "|[-0.2546376588361...|      0.0|\n",
      "|[-0.8506592533152...|      0.0|\n",
      "|[-0.0559637940097...|      0.0|\n",
      "|[0.27515931403420...|      0.0|\n",
      "|[-1.0493331181415...|      0.0|\n",
      "|[-1.1155577397503...|      1.0|\n",
      "|[1.59965174621001...|      0.0|\n",
      "|[0.01026082759904...|      0.0|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_balanced.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9eb7b277-b593-4e17-8295-3b7f56efa6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after balancing dataset: 531167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows after balancing dataset: {df_balanced.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be72901f-fe34-4d85-8f4c-42f306c944e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 57:=================================================>        (6 + 1) / 7]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 266045, 1.0: 265122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "counts = df_balanced.groupBy(\"cancelled\").count().collect()\n",
    "cnts = {row[\"cancelled\"]: row[\"count\"] for row in counts}\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4b91b-7eff-401a-9c44-c4af2afb132d",
   "metadata": {},
   "source": [
    "6. Split dataset into train / val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24d5f486-60a3-4587-9ae1-7d3355b51e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"serve-DataFrame\" java.net.SocketTimeoutException: Accept timed out\n",
      "\tat java.net.PlainSocketImpl.socketAccept(Native Method)\n",
      "\tat java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)\n",
      "\tat java.net.ServerSocket.implAccept(ServerSocket.java:560)\n",
      "\tat java.net.ServerSocket.accept(ServerSocket.java:528)\n",
      "\tat org.apache.spark.security.SocketAuthServer$$anon$1.run(SocketAuthServer.scala:65)\n",
      "[Stage 75:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 425472 Valid size: 105695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# train_df, val_df = df_balanced.randomSplit([0.8, 0.2], seed=42)\n",
    "# print(\"Train size:\", train_df.count(), \"Valid size:\", val_df.count())\n",
    "\n",
    "df_class_0 = df_balanced.filter(F.col(\"cancelled\") == 0.0)\n",
    "df_class_1 = df_balanced.filter(F.col(\"cancelled\") == 1.0)\n",
    "train_0, val_0 = df_class_0.randomSplit([0.8, 0.2], seed=42)\n",
    "train_1, val_1 = df_class_1.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_df = train_0.unionAll(train_1)\n",
    "val_df = val_0.unionAll(val_1)\n",
    "print(\"Train size:\", train_df.count(), \"Valid size:\", val_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7765a84a-1de3-41be-91fa-dd8d046f7501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 78:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: 213099, 1.0: 212373}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "counts = train_df.groupBy(\"cancelled\").count().collect()\n",
    "cnts = {row[\"cancelled\"]: row[\"count\"] for row in counts}\n",
    "print(cnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d5bf714-377f-463e-ab01-8f2233222789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 81:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|cancelled|\n",
      "+--------------------+---------+\n",
      "|[-1.6321097882989...|      0.0|\n",
      "|[-1.6188648639771...|      0.0|\n",
      "|[-1.5393953180466...|      0.0|\n",
      "|[-1.5393953180466...|      0.0|\n",
      "|[-1.4996605450813...|      0.0|\n",
      "|[-1.4864156207596...|      0.0|\n",
      "|[-1.4864156207596...|      0.0|\n",
      "|[-1.4864156207596...|      0.0|\n",
      "|[-1.4731706964378...|      0.0|\n",
      "|[-1.4731706964378...|      0.0|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ce020bc1-affc-4589-9bd7-0e950c21a046",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 82:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            features|cancelled|\n",
      "+--------------------+---------+\n",
      "|[-1.6056199396554...|      0.0|\n",
      "|[-1.4864156207596...|      0.0|\n",
      "|[-1.4864156207596...|      0.0|\n",
      "|[-1.4731706964378...|      0.0|\n",
      "|[-1.4599257721160...|      0.0|\n",
      "|[-1.4599257721160...|      0.0|\n",
      "|[-1.4599257721160...|      0.0|\n",
      "|[-1.4466808477943...|      0.0|\n",
      "|[-1.4466808477943...|      0.0|\n",
      "|[-1.4466808477943...|      0.0|\n",
      "+--------------------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "val_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05be07aa-6e9e-429c-bea7-5dfdbbad9f08",
   "metadata": {},
   "source": [
    "7. Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56ba10dd-de8c-40f9-bf4f-2dfe215bc799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def run(command):\n",
    "    return os.popen(command).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0dadb385-6649-4706-bbf7-5a349334c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.select(\"features\", \"label\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"json\")\\\n",
    "#     .save(\"BigData-project/data/train\")\n",
    "\n",
    "# run(\"hdfs dfs -cat BigData-project/data/train/*.json > data/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867ad247-8d71-41cf-8874-b700f2600d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_df.select(\"features\", \"label\")\\\n",
    "#     .coalesce(1)\\\n",
    "#     .write\\\n",
    "#     .mode(\"overwrite\")\\\n",
    "#     .format(\"json\")\\\n",
    "#     .save(\"BigData-project/data/test\")\n",
    "\n",
    "# run(\"hdfs dfs -cat BigData-project/data/val/*.json > data/val.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dab9b1b",
   "metadata": {},
   "source": [
    "### ML modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5e4fcc-cf0b-4f4e-a7a1-f19b40d99339",
   "metadata": {},
   "source": [
    "#### Model 1: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "94f79b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col = \"cancelled\"\n",
    "features_col = \"features\"\n",
    "\n",
    "lr = LogisticRegression(labelCol=label_col, featuresCol=features_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "20c726d3-9002-42d9-9c99-bd260e083e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .addGrid(lr.maxIter, [10, 50]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f78757a0-7704-4e84-b27d-3ce1337d416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator1 = BinaryClassificationEvaluator(labelCol=label_col, rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2498eb5-a4f5-482c-b389-d0a52bd3f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lr = CrossValidator(estimator=lr,\n",
    "                       estimatorParamMaps=paramGrid_lr,\n",
    "                       evaluator=evaluator1,\n",
    "                       numFolds=3,\n",
    "                       parallelism=5,\n",
    "                       seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9996018f-88b4-4663-a1d7-18e244937f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression with Cross-Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/08 08:03:47 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "[Stage 2085:>(9 + 2) / 14][Stage 2087:>(0 + 0) / 14][Stage 2089:>(0 + 0) / 14]  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/multiprocessing/pool.py:856\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining Logistic Regression with Cross-Validation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cv_model_lr = \u001b[43mcv_lr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLogistic Regression training complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyspark/ml/base.py:205\u001b[39m, in \u001b[36mEstimator.fit\u001b[39m\u001b[34m(self, dataset, params)\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy(params)._fit(dataset)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[32m    210\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/pyspark/ml/tuning.py:847\u001b[39m, in \u001b[36mCrossValidator._fit\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    841\u001b[39m train = datasets[i][\u001b[32m0\u001b[39m].cache()\n\u001b[32m    843\u001b[39m tasks = \u001b[38;5;28mmap\u001b[39m(\n\u001b[32m    844\u001b[39m     inheritable_thread_target,\n\u001b[32m    845\u001b[39m     _parallelFitTasks(est, train, eva, validation, epm, collectSubModelsParam),\n\u001b[32m    846\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubModel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics_all\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcollectSubModelsParam\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/multiprocessing/pool.py:861\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28mself\u001b[39m._pool = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_cond\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    863\u001b[39m     item = \u001b[38;5;28mself\u001b[39m._items.popleft()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/threading.py:327\u001b[39m, in \u001b[36mCondition.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m         \u001b[43mwaiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m         gotit = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    329\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Logistic Regression with Cross-Validation...\")\n",
    "cv_model_lr = cv_lr.fit(train_df)\n",
    "print(\"Logistic Regression training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d274f5b9-7c8e-4943-95b3-ee337beaab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_model = cv_model_lr.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b886cad-7287-4c48-adc4-ac751c886224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2091:(11 + 1) / 14][Stage 2093:>(7 + 0) / 14][Stage 2095:>(2 + 1) / 14]  \r"
     ]
    }
   ],
   "source": [
    "print(\"\\nBest Logistic Regression Model Parameters:\")\n",
    "for param in best_lr_model.extractParamMap():\n",
    "    if param.name in ['regParam', 'elasticNetParam', 'maxIter']:\n",
    "        print(f\"  {param.name}: {best_lr_model.getOrDefault(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7c0550-aa1d-43f6-84ab-cd69df6d9b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr = best_lr_model.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3fd40-fb12-46ae-bee4-5d8ff2226af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lr_test = evaluator1.evaluate(predictions_lr)\n",
    "print(f\"Logistic Regression - Test AUC: {auc_lr_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941de998-5956-4ae7-871e-31a3f6deda7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More detailed metrics (Precision, Recall, F1 for the positive class '1.0' - Cancelled)\n",
    "def get_detailed_metrics(predictions_df, model_name=\"Model\"):\n",
    "    print(f\"\\nDetailed Metrics for {model_name} on Test Data:\")\n",
    "    # Ensure prediction and label are float for MulticlassMetrics\n",
    "    preds_and_labels = predictions_df.select(\n",
    "        F.col(\"prediction\").cast(DoubleType()),\n",
    "        F.col(label_col).cast(DoubleType())\n",
    "    ).rdd.map(lambda r: (r[0], r[1]))\n",
    "\n",
    "    metrics = MulticlassMetrics(preds_and_labels)\n",
    "    print(f\"  Confusion Matrix:\\n{metrics.confusionMatrix().toArray()}\")\n",
    "    # For binary, class 1.0 is usually the positive class (Cancelled)\n",
    "    print(f\"  Precision (Cancelled=1.0): {metrics.precision(1.0):.4f}\")\n",
    "    print(f\"  Recall (Cancelled=1.0): {metrics.recall(1.0):.4f}\")\n",
    "    print(f\"  F1-Score (Cancelled=1.0): {metrics.fMeasure(1.0):.4f}\")\n",
    "    print(f\"  Accuracy: {metrics.accuracy:.4f}\")\n",
    "    return metrics.precision(1.0), metrics.recall(1.0), metrics.fMeasure(1.0) # Return for comparison table\n",
    "\n",
    "\n",
    "lr_precision, lr_recall, lr_f1 = get_detailed_metrics(predictions_lr, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0f691-f2e3-44de-b583-96cef98a5eab",
   "metadata": {},
   "source": [
    " Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b508c146-5652-4db1-bcd4-1cf33b1d9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "model_output_path_lr = f\"BigData-project/{team}/models/logistic_regression_model\"\n",
    "best_lr_model = cv_model_lr.bestModel\n",
    "pprint(best_lr_model.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27df012-ac1c-4204-bda8-65d9bea242c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lr_model.write().overwrite().save(model_output_path_lr)\n",
    "run(\"hdfs dfs -get BigData-project/models/logistic_regression_model models/logistic_regression_model\")\n",
    "print(f\"Saved best Logistic Regression model to: {model_output_path_lr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdcc65-fbac-4eda-9d63-3efb05bf49d6",
   "metadata": {},
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f8158-bde5-4d58-87fa-bf6b60abdd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output_path_lr = f\"BigData-project/{team}/output/lr_model_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2040a87-47ba-4935-bcfb-e87574176963",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr.select(label_col, \"prediction\") \\\n",
    "    .coalesce(1) \\\n",
    "    .write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(predictions_output_path_lr)\n",
    "\n",
    "\n",
    "print(f\"Saved Logistic Regression predictions to: {predictions_output_path_lr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44fd41-775c-4482-9420-89acd9724e66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d593f-e060-4a3b-a684-e38be42f8368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406422f4-db2a-4bd3-ab54-7fb2dd695958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3258722b-9b8d-4378-919f-0a489d45c2e0",
   "metadata": {},
   "source": [
    "#### Model 2 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fc3de6-b94e-44cc-9258-e7f8e5b4df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol=label_col, featuresCol=features_col, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac24f484-e848-4438-9191-367c5c71e6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(rf.featureSubsetStrategy, [\"sqrt\", \"log2\"]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3155335-5b15-4ce2-bd9c-eec82ca4c72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_rf = CrossValidator(estimator=rf,\n",
    "                       estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=evaluator,\n",
    "                       numFolds=3,\n",
    "                       parallelism=5,\n",
    "                       seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bc0f9-712d-42f1-8dc4-846e87317bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator2 = BinaryClassificationEvaluator(labelCol=label_col, rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948c733a-8954-4201-8a5c-5753706dc92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Random Forest with Cross-Validation...\")\n",
    "cv_model_rf = cv_rf.fit(train_df)\n",
    "print(\"Random Forest training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0c448-cb08-47b9-a5a9-9493fc9fbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model = cv_model_rf.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa3ff99-1486-4e32-9234-da16a8e1c47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nBest Random Forest Model Parameters:\")\n",
    "for param in best_rf_model.extractParamMap():\n",
    "     if param.name in ['numTrees', 'maxDepth', 'featureSubsetStrategy']: # Print relevant params\n",
    "        print(f\"  {param.name}: {best_rf_model.getOrDefault(param)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4322bf-556b-4f8d-8ecd-693ea821c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf = best_rf_model.transform(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba08c9e8-f34d-4f8a-9bd9-3fd4a36060cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_rf_test = evaluator2.evaluate(predictions_rf)\n",
    "print(f\"Random Forest - Test AUC: {auc_rf_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba81fb7-d816-4e8c-b289-3eea283aa8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_precision, rf_recall, rf_f1 = get_detailed_metrics(predictions_rf, \"Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9730dd-d662-4d09-a41d-cadbf21bce22",
   "metadata": {},
   "source": [
    "Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665544d-b767-4263-8043-4d53a4f7c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output_path_rf = f\"BigData-project/{team}/models/random_forest_model\"\n",
    "best_rf_model = cv_model_rf.bestModel\n",
    "pprint(best_rf_model.extractParamMap())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba85f6-0a62-406a-abca-6c36a9b71992",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_model.write().overwrite().save(model_output_path_rf)\n",
    "run(\"hdfs dfs -get BigData-project/models/random_forest_model models/random_forest_model\")\n",
    "print(f\"Saved best Random Forest model to: {model_output_path_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7955c94-becb-4783-9338-337b04be8472",
   "metadata": {},
   "source": [
    "Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da25b29-019f-46ee-bdbb-3deea93e8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output_path_rf = f\"BigData-project/{team}/output/rf_model_predictions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e73b6b-f05c-49a3-81fb-ea31f9738bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rf.select(label_col, \"prediction\") \\\n",
    "    .coalesce(1) \\\n",
    "    .write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"sep\", \",\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .save(predictions_output_path_rf)\n",
    "\n",
    "\n",
    "print(f\"Saved Random Forest predictions to: {predictions_output_path_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4aee1d-cf33-429c-a67e-1a3381b937c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d853017-7fd3-42de-b04d-de2d4f657505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a1e87-0d32-40b7-bb99-7573b7d47bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c410a5-a48d-4cce-8c31-c47d0b7a027e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950d5812-3ce8-462e-a90e-86668e227674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d80afb0-e42d-4aa0-a6e0-3b745e640756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae5fc0b-8cdb-4b18-a3a4-277687b319dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83750f0e-038f-4ce0-bb9b-31f15d2de072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33195553-7d46-43c3-ac14-f480013dd505",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd6b2b-b952-47f2-b9a5-ae820df285b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eea0e1-7503-4be5-af52-1a66b66dac84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build pre-processing stages (common for both models)\n",
    "preprocessing_stages = indexers + encoders + [temp_numerical_assembler, scaler, vector_assembler]\n",
    "\n",
    "pipeline_lr = Pipeline(stages=preprocessing_stages + [lr])\n",
    "pipeline_rf = Pipeline(stages=preprocessing_stages + [rf])\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Cancelled\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20, 50]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "cv_lr = CrossValidator(estimator=pipeline_lr, estimatorParamMaps=paramGrid_lr, evaluator=evaluator, numFolds=3, parallelism=4, seed=42)\n",
    "cv_rf = CrossValidator(estimator=pipeline_rf, estimatorParamMaps=paramGrid_rf, evaluator=evaluator, numFolds=3, parallelism=4, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70548561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training Logistic Regression ---\")\n",
    "cv_model_lr = cv_lr.fit(train_data)\n",
    "best_model_lr = cv_model_lr.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f092023a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Training Random Forest ---\")\n",
    "cv_model_rf = cv_rf.fit(train_data)\n",
    "best_model_rf = cv_model_rf.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e9fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluate Models ---\n",
    "print(\"--- Evaluating Models on Test Data ---\")\n",
    "predictions_lr = best_model_lr.transform(test_data)\n",
    "predictions_rf = best_model_rf.transform(test_data)\n",
    "\n",
    "auc_pr_lr = evaluator.evaluate(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detailed_metrics(predictions_df, label_col=\"Cancelled\", pred_col=\"prediction\"):\n",
    "    \"\"\"Calculates and returns detailed classification metrics.\"\"\"\n",
    "    preds_and_labels = predictions_df.select(pred_col, label_col).rdd.map(lambda r: (float(r[0]), float(r[1])))\n",
    "    metrics = MulticlassMetrics(preds_and_labels)\n",
    "    \n",
    "    metrics_dict = {\n",
    "        \"confusion_matrix\": metrics.confusionMatrix().toArray().tolist(),\n",
    "        \"precision_0\": metrics.precision(0.0),\n",
    "        \"recall_0\": metrics.recall(0.0),\n",
    "        \"f1_0\": metrics.fMeasure(0.0),\n",
    "        \"precision_1\": metrics.precision(1.0), # For Cancelled\n",
    "        \"recall_1\": metrics.recall(1.0),       # For Cancelled\n",
    "        \"f1_1\": metrics.fMeasure(1.0),         # For Cancelled\n",
    "        \"accuracy\": metrics.accuracy\n",
    "    }\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_metrics_lr = get_detailed_metrics(predictions_lr)\n",
    "print(f\"Logistic Regression - Test AreaUnderPR: {auc_pr_lr}\")\n",
    "print(f\"Logistic Regression - Test Precision (Cancelled): {detailed_metrics_lr['precision_1']}\")\n",
    "print(f\"Logistic Regression - Test Recall (Cancelled): {detailed_metrics_lr['recall_1']}\")\n",
    "print(f\"Logistic Regression - Test F1 (Cancelled): {detailed_metrics_lr['f1_1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcbb6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_pr_rf = evaluator.evaluate(predictions_rf)\n",
    "detailed_metrics_rf = get_detailed_metrics(predictions_rf)\n",
    "print(f\"Random Forest - Test AreaUnderPR: {auc_pr_rf}\")\n",
    "print(f\"Random Forest - Test Precision (Cancelled): {detailed_metrics_rf['precision_1']}\")\n",
    "print(f\"Random Forest - Test Recall (Cancelled): {detailed_metrics_rf['recall_1']}\")\n",
    "print(f\"Random Forest - Test F1 (Cancelled): {detailed_metrics_rf['f1_1']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04083c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Models and Predictions ---\n",
    "print(\"--- Saving Models and Outputs ---\")\n",
    "model1_path_hdfs = \"project/models/flight_cancellation_lr_model\"\n",
    "model2_path_hdfs = \"project/models/flight_cancellation_rf_model\"\n",
    "\n",
    "best_model_lr.write().overwrite().save(model1_path_hdfs)\n",
    "print(f\"Saved Logistic Regression model to: {model1_path_hdfs}\")\n",
    "best_model_rf.write().overwrite().save(model2_path_hdfs)\n",
    "print(f\"Saved Random Forest model to: {model2_path_hdfs}\")\n",
    "\n",
    "predictions_lr.select(\"Cancelled\", \"prediction\") \\\n",
    "    .coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model1_lr_predictions\")\n",
    "print(\"Saved LR predictions to project/output/model1_lr_predictions\")\n",
    "\n",
    "predictions_rf.select(\"Cancelled\", \"prediction\") \\\n",
    "    .coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model2_rf_predictions\")\n",
    "print(\"Saved RF predictions to project/output/model2_rf_predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c77de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Evaluation Comparison ---\n",
    "evaluation_summary_data = [\n",
    "    (\"Logistic Regression\", auc_pr_lr, detailed_metrics_lr['precision_1'], detailed_metrics_lr['recall_1'], detailed_metrics_lr['f1_1']),\n",
    "    (\"Random Forest\",       auc_pr_rf, detailed_metrics_rf['precision_1'], detailed_metrics_rf['recall_1'], detailed_metrics_rf['f1_1'])\n",
    "]\n",
    "eval_schema = [\"ModelName\", \"AreaUnderPR\", \"Precision_Cancelled\", \"Recall_Cancelled\", \"F1_Score_Cancelled\"]\n",
    "evaluation_df = spark.createDataFrame(evaluation_summary_data, schema=eval_schema)\n",
    "evaluation_df.show(truncate=False)\n",
    "evaluation_df.coalesce(1).write.mode(\"overwrite\").format(\"csv\") \\\n",
    "    .option(\"header\", \"true\").save(\"project/output/model_evaluation_comparison\")\n",
    "print(\"Saved evaluation comparison to project/output/model_evaluation_comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf1841",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.unpersist()\n",
    "test_data.unpersist()\n",
    "spark.stop()\n",
    "print(\"--- Pipeline Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f846a3f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cf607",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pyspark 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
